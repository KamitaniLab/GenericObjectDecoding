# Generic Object Decoding

This repository contains the data and demo codes for replicating results in our paper: [Horikawa and Kamitani (2017) Generic decoding of seen and imagined objects using hierarchical visual features. Nature Communications 8:15037](https://www.nature.com/articles/ncomms15037).
The generic object decoding approach enabled decoding of arbitrary object categories including those not used in model training.

## Dataset

- Raw fMRI data: [OpenNeuro](https://openneuro.org/datasets/ds001246)
- Preprocessed fMRI data and image features: [figshare](https://figshare.com/articles/Generic_Object_Decoding/7387130)
- Stimulus images: upon request via <https://forms.gle/ujvA34948Xg49jdn9>

## Code

Demo programs for Matlab and Python are available in [code/matlab](code/matlab/) and [code/python](code/python), respectively.
See README.md in each directory for the details.

## Note

### Visual images

For copyright reasons, we do not make the visual images used in our experiments publicly available.
You can request us to share the stimulus images at <https://forms.gle/ujvA34948Xg49jdn9>.

Stimulus images used for higher visual area locazlier experiments in this study are available via <https://forms.gle/c6HGatLrt7JtTGQk7>.

Some of the test images were taken from ILSVRC 2012 training images. See [data/stimulus_info_ImageNetTest.csv](https://github.com/KamitaniLab/GenericObjectDecoding/blob/master/data/stimulus_info_ImageNetTest.csv) for the list of images included in ILSVRC 2012 training images.
